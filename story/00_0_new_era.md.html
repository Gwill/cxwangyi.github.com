<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
   <meta http-equiv="content-type" content="text/html; charset=utf-8" />
   <meta name="author" content="Yi Wang" />
   <link href="http://kevinburke.bitbucket.org/markdowncss/markdown.css" rel="stylesheet"></link>
</head>
<body>
<h2>一个新时代</h2>

<h3>起源</h3>

<p>分布式机器学习是随着“大数据”概念兴起的。在有大数据之前，有很多研究工作为了让机器学习算法更快，而利多多个处理器。这类工作通常称为“并行计算”或者“并行机器学习”，其核心目标是把计算任务拆解成多个小的任务，分配到多个处理器上做计算。分布式计算或者分布式机器学习除了要把计算任务分布到多个处理器上，更重要的是把数据（包括训练数据以及中间结果）分布开来。因为在大数据时代，一台机器的硬盘往往装不下全部数据，或者即使装下了，也会受限于机器的I/O通道的带宽，以至于访问速度很慢。为了更大的存储容量、吞吐量以及容错能力，我们都希望把数据分布在多台计算机上。</p>

<p>那么什么样的数据大到一台机器甚至几百台机器的硬盘都装不下呢？要知道，现在很多服务器的硬盘空间都是数TB的了！其实这样的大数据有很多。比如搜索引擎要爬下很多很多的网页，对其内容做分析并建立索引。有多少网页呢？这个数字很难估计，因为这是随时间变化的。在Web 2.0出现之前，全球网页数量的增长相对稳定，因为网页都是专业人员编辑的。而由于各种Web 2.0工具帮助用户建立自己的网页，比如博客、甚至微博，所以网页数量呈指数速度递增。</p>

<p>另一种典型的大数据是电商网站上的用户行为数据。比如在亚马逊或者淘宝上，每天都很多用户看到了很多推荐的商品，并且点击了其中一些。这些用户点击推荐商品的行为会被亚马逊和淘宝的服务器记录下来，作为分布式机器学习系统的输入。输出是一个数学模型，可以预测一个用户喜欢看到哪些商品，从而在下一次展示推荐商品的时候，多展示那些用户喜欢的。</p>

<p>类似的，在互联网广告系统中，展示给用户的广告、以及用户点击的广告也都会被记录下来，作为机器学习系统的数据，训练点击率预估模型。在下一次展示推荐商品时，这些模型会被用来预估每个商品如果被展示之后，有多大的概率被用户点击。其中预估点击率高的商品，往往展示在预估点击率低的商品之前，从而赢得实际上比较高的点击率。</p>

<p>从上面的例子我们可以看出来，这些大数据之所以大，是因为它们记录的是数十亿互联网用户的行为。而人们每天都会产生行为，以至于百度、阿里、腾讯、奇虎、搜狗这样的公司的互联网服务每天收集到很多很多块硬盘才能装下的数据。而且这些数据随时间增加，永无止境。虽然对“大数据”的具体定义见人见智，但是互联网用户的行为数据，毫无疑问地被公认为大数据了。</p>

<h3>价值</h3>

<p>机器学习的应用由来已久。大家可能还记得十几年前IBM推出的语音识别和输入系统ViaVoice。这个系统使用的声学模型和语言模型是用人工收集整理和标注的数据训练的。当年因为IBM财大气粗，收集和整理了很多数据，所以ViaVoice的识别准确率在同类产品中遥遥领先。但是，ViaVoice很难保证能识别各种口音的人。所以IBM的工程师们设计了一个自动适应的功能——通过让用户标注没能正确识别的语音对应的文本，ViaVoice可以针对主任的口音做特别的优化。</p>

<p>今天，大家可以通过互联网使用Google的语音识别系统。我们会发现，不管使用者口音如何，Google的语音识别系统几乎都能准确识别，以至于几乎不再需要“适应主人的口音”。而且Google的系统支持的语言种类也更多。这其中的奥妙就在于“大数据”。</p>

<p>在Google发布语音识别引擎之前，先有语音搜索服务。在语音搜索服务之前，有一个打电话查询的服务。实际上，正式这个电话服务收集了很多用户的语音输入。这部分数据经过人工标注，称为了训练语言模型和声学模型的第一批数据。随后发布的语音搜索收集了世界各地更多互联网用户的声音，加上半自动标注系统的引入，训练数据大大丰富了。训练数据越多，能覆盖的口音和语种越多，机器学习得到的模型的识别准确率也就越高。以至于当Google发布语音识别引擎之初，识别率就远高于依赖人工标注训练数据的IBM ViaVoice。随着语音识别服务被很多手机应用和桌面应用使用，它能采集更多用户的语音输入，模型的准确性会不断得到提高。</p>

<p>从上面例子我们可以看出，因为互联网服务收集的数据是万万千千用户的行为的体现，而人类行为是人类智能的结果。所以如果我们能设计分布式机器学习系统，能从大数据中归纳规律，我们实际上就在归纳整个人类的知识库。这个听起来很神奇，实际上在上面的例子里，Google已经做到了。在这一系列的最后一节里，我们会介绍我们开发的一个语义学习系统，它从上千亿条文本数据中，归纳汉语中上百万的“语义”。随后，只要用户输入任何一段文本，这个系统可以利用训练好的模型在一毫秒之内，理解文本中表达的“语义”。这个理解过程确保消除文本中的歧义，从而让搜索引擎、广告系统、推荐系统等应用更好地理解用户需求。</p>

<p>简言之，互联网使得人类第一次有机会收集全人类的行为数据。从而为机器学习这一持续了数十年的研究方向提供了全新的机会——分布式机器学习——从互联网数据中归纳这个人类的知识，从而让机器比任何一个个人都要“聪明”。</p>
</html>
